{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41214791",
   "metadata": {},
   "source": [
    "## install all the packeges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca62710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\pegasus\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in f:\\pegasus\\lib\\site-packages (from transformers) (1.22.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.0-py3-none-any.whl (77 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Downloading tokenizers-0.11.6-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.3.15-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\pegasus\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in f:\\pegasus\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: colorama in f:\\pegasus\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.1.2-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: six in f:\\pegasus\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, regex, pyyaml, joblib, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed certifi-2021.10.8 charset-normalizer-2.0.12 click-8.1.2 filelock-3.6.0 huggingface-hub-0.5.0 idna-3.3 joblib-1.1.0 pyyaml-6.0 regex-2022.3.15 requests-2.27.1 sacremoses-0.0.49 tokenizers-0.11.6 tqdm-4.64.0 transformers-4.17.0 urllib3-1.26.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'F:\\pegasus\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44dcd9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'F:\\pegasus\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b54a9e",
   "metadata": {},
   "source": [
    "### import packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5721751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch \n",
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ea960",
   "metadata": {},
   "source": [
    "### Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7deb5904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2131fefc3bb9406db66291b1604ecbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c1e48fd030439ea9cfefedc7025b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33e9ce3746c465da03920391e46bc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb0cbd5341a4227b9277ef0d848339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " #Load tokenizer \n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576dd5c",
   "metadata": {},
   "source": [
    "### load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68e8ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9512511f2244440bf6aed33ca8c3181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef1b43",
   "metadata": {},
   "source": [
    "### Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c487f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Python is an interpreted high-level general-purpose programming language. Its design philosophy emphasizes code readability with its use of significant indentation. Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[30]\n",
    "\n",
    "Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[31]\n",
    "\n",
    "Guido van Rossum began working on Python in the late 1980s, as a successor to the ABC programming language, and first released it in 1991 as Python 0.9.0.[32] Python 2.0 was released in 2000 and introduced new features, such as list comprehensions and a garbage collection system using reference counting. Python 3.0 was released in 2008 and was a major revision of the language that is not completely backward-compatible. Python 2 was discontinued with version 2.7.18 in 2020.[33]\n",
    "\n",
    "Python consistently ranks as one of the most popular programming languages.[34][35][36][37]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662a8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0c0d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11994,   117,   142, 15186,   281,   121,  3393,   956,   121, 14621,\n",
       "          3661,  1261,   107,  3096,   354,  4679, 18390,   929, 39331,   122,\n",
       "           203,   207,   113,  1225, 58339,   107,  3096,  1261, 38059,   130,\n",
       "           210,   130,   203,  2951,   121,  8321,  1014,  2560,   112,   225,\n",
       "         19003,  1094,   786,   108,  8789,   929,   118,   360,   111,   423,\n",
       "           121,  5129,   844,   107,  4101,  4311,  1100, 11994,   117, 22717,\n",
       "           121,  7155,   252,   111,  9041,   121, 83800,   107,   168,  3000,\n",
       "          1079,  3661, 50877,   108,   330,  7314,   143, 24899,   108, 22000,\n",
       "           312,  2951,   121,  8321,   111,  3819,  3661,   107,   168,   117,\n",
       "           432,  2540,   130,   114,   198, 18077,   144, 32300,   953,   194,\n",
       "          1261,   640,   112,   203,  2250,   971,  2400,   107,  4101, 10822,\n",
       "          1100, 58937,  4406,  7366,  3707,  1219,   375,   124, 11994,   115,\n",
       "           109,  1095,  5940,   116,   108,   130,   114, 15749,   112,   109,\n",
       "          8172,  3661,  1261,   108,   111,   211,  1291,   126,   115, 12086,\n",
       "           130, 11994, 21544,   107, 24613,  4101,  6695,  1100, 11994,  4586,\n",
       "           140,  1291,   115,  3555,   111,  2454,   177,   556,   108,   253,\n",
       "           130,   467, 17673,   116,   111,   114,  9041,   949,   327,   303,\n",
       "          2334,  8742,   107, 11994,  9179,   140,  1291,   115,  3390,   111,\n",
       "           140,   114,   698, 11827,   113,   109,  1261,   120,   117,   146,\n",
       "          1127, 17868,   121, 37804,   107, 11994,   280,   140, 17921,   122,\n",
       "           824, 21672,   107,  4876,   115, 12573,  4101,  9773,  1100, 11994,\n",
       "          4409,  7329,   130,   156,   113,   109,   205,   785,  3661,  4482,\n",
       "           107,  4101, 12365, 32887,  7393, 32887,  9368, 32887, 13185,  1100,\n",
       "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09aee123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fe694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 11994,   117,   114,  3661,  1261,  1184,   141, 58937,  4406,\n",
       "         7366,  3707,   107,     1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9833a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is a programming language developed by Guido van Rossum.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce93d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\"The tower is 324 metres (1,063 ft) tall \n",
    "about the same height as an 81-storey building, \n",
    "and the tallest structure in Paris. Its base is square,\n",
    "measuring 125 metres (410 ft) on each side. During its construction,\n",
    "the Eiffel Tower surpassed the Washington Monument to become ,\n",
    "the tallest man-made structure in the world,\n",
    "a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. \n",
    "It was the first structure to reach a height of 300 metres.\n",
    "Due to the addition of a broadcasting aerial at the top of the tower in 1957,\n",
    "it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters\n",
    ", the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df310b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text2, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3dfee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  198,   159,  5998,   117, 56966,  7641,  4653,   108, 63292,  4954,\n",
       "           158,  3930,   160,   109,   310,  3098,   130,   142, 13042,   121,\n",
       "         23761,   563,   108,   111,   109, 22246,  1557,   115,  3165,   107,\n",
       "          3096,  1217,   117,  2151,   108,  6542, 10557,  7641,   143, 27789,\n",
       "          4954,   158,   124,   276,   477,   107,  2348,   203,  1187,   108,\n",
       "           109, 37695,  6817, 23861,   109,  1741, 20551,   112,   460,   110,\n",
       "           108,   109, 22246,   729,   121,  4109,  1557,   115,   109,   278,\n",
       "           108,   114,  1560,   126,   886,   118,  6820,   231,   430,   109,\n",
       "         15528,  3671,   115,   351,   859,   672,   140,  1554,   115,  9844,\n",
       "           107,   168,   140,   109,   211,  1557,   112,  1111,   114,  3098,\n",
       "           113,  3251,  7641,   107,  5223,   112,   109,   663,   113,   114,\n",
       "         16071, 11676,   134,   109,   349,   113,   109,  5998,   115, 20636,\n",
       "           108,   126,   117,   239, 17916,   197,   109, 15528,  3671,   141,\n",
       "         27815,  7641, 23121,  4954,   250,   110, 64898, 48453,   110,   108,\n",
       "           109, 37695,  6817,   117,   109,   453, 22246,   294,   121, 11570,\n",
       "          1557,   115,  2481,   244,   109,  4315,  4380, 15258, 22947,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffbd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce2a0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   139, 37695,  6817,   117,   114, 11023,   115,  3165,   108,\n",
       "         2481,   107,     1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecc76d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is a landmark in Paris, France.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e534ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
